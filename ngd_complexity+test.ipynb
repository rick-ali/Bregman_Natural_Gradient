{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "# Set manual seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Simple MLP class using PyTorch\n",
        "class SimpleMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleMLP, self).__init__()\n",
        "        # Define layers\n",
        "        self.fc1 = nn.Linear(2, 4)  # Input layer to hidden layer\n",
        "        self.fc2 = nn.Linear(4, 1)  # Hidden layer to output layer\n",
        "        self.sigmoid = nn.Sigmoid()  # Activation function\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.sigmoid(self.fc1(x))  # Apply sigmoid activation function after first layer\n",
        "        x = self.sigmoid(self.fc2(x))  # Apply sigmoid activation function to produce output\n",
        "        return x\n",
        "\n",
        "# Create a simple MLP instance\n",
        "mlp = SimpleMLP()\n",
        "\n",
        "# Define a binary cross entropy loss for boolean output\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Optimizer (Stochastic Gradient Descent)\n",
        "optimizer = optim.SGD(mlp.parameters(), lr=0.1)\n",
        "\n",
        "# Input and output data (Boolean)\n",
        "inputs = torch.tensor([[0., 0.], [0., 1.], [1., 0.], [1., 1.]], dtype=torch.float32)\n",
        "outputs = torch.tensor([[0.], [1.], [1.], [0.]], dtype=torch.float32)\n",
        "\n",
        "# Training loop\n",
        "epochs = 1000\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()  # Clear gradients for the next train\n",
        "    output = mlp(inputs)  # Forward pass: Compute predicted output by passing inputs to the model\n",
        "    loss = criterion(output, outputs)  # Calculate loss\n",
        "    loss.backward()  # Backward pass: compute gradient of the loss with respect to model parameters\n",
        "    optimizer.step()  # Perform a single optimization step (parameter update)\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Test the MLP\n",
        "with torch.no_grad():  # We don't need gradients for testing\n",
        "    predicted = mlp(inputs).round()  # Apply rounding to get boolean outputs\n",
        "    print(f\"Predicted boolean outputs:\\n{predicted}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tsx55sQQSa-7",
        "outputId": "1929f7f7-268b-4f9e-d15e-66a314a44453"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1000], Loss: 0.7723\n",
            "Epoch [101/1000], Loss: 0.6926\n",
            "Epoch [201/1000], Loss: 0.6924\n",
            "Epoch [301/1000], Loss: 0.6923\n",
            "Epoch [401/1000], Loss: 0.6921\n",
            "Epoch [501/1000], Loss: 0.6919\n",
            "Epoch [601/1000], Loss: 0.6917\n",
            "Epoch [701/1000], Loss: 0.6914\n",
            "Epoch [801/1000], Loss: 0.6911\n",
            "Epoch [901/1000], Loss: 0.6907\n",
            "Predicted boolean outputs:\n",
            "tensor([[0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlp = SimpleMLP()\n",
        "with torch.no_grad():\n",
        "\n",
        "  p = mlp(inputs).round()\n",
        "\n",
        "s = ((np.array(p.flatten())).astype(np.int32))\n",
        "s1 = ''.join(map(str,s)) #this the representation we are looking for therefore (2^2^no of inputs)\n",
        "\n",
        "lz_complexity(s1)"
      ],
      "metadata": {
        "id": "Qx7k4d_Qvjzc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ade5326-311d-4955-d2d6-4d5dc8cdcc17"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.0"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strs = ['0000','0001','0010','0011',\n",
        "        '0100','0101','0110','0111',\n",
        "        '1000','1001','1010','1011',\n",
        "        '1100','1101','1110','1111']\n",
        "\n",
        "input_list = ['00','01','10','11']        # I am checking how the complexity varies as the functions change."
      ],
      "metadata": {
        "id": "5-O2lUyBdJKa"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for s in strs:\n",
        "  print(lz_complexity(s))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrrynfpGeh9i",
        "outputId": "81b61659-9115-4105-8463-fe6f4bca9026"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0\n",
            "6.0\n",
            "5.0\n",
            "6.0\n",
            "5.0\n",
            "6.0\n",
            "6.0\n",
            "6.0\n",
            "6.0\n",
            "6.0\n",
            "6.0\n",
            "5.0\n",
            "6.0\n",
            "5.0\n",
            "6.0\n",
            "2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for s in strs:\n",
        "  print(entropy(s))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOVsWzRceszu",
        "outputId": "e3b6c408-374d-44a0-ab50-f7752d4cc0d7"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-2.0\n",
            "0.8112781244591328\n",
            "0.8112781244591328\n",
            "1.0\n",
            "0.8112781244591328\n",
            "1.0\n",
            "1.0\n",
            "0.8112781244591328\n",
            "0.8112781244591328\n",
            "1.0\n",
            "1.0\n",
            "0.8112781244591328\n",
            "1.0\n",
            "0.8112781244591328\n",
            "0.8112781244591328\n",
            "-2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import *\n",
        "def model(value, input):\n",
        "  a = input_list.index(input)\n",
        "  return int(strs[value][a])\n",
        "\n",
        "for s in strs:\n",
        "  b = strs.index(s)\n",
        "  c = partial(model, b)\n",
        "  print(generalisation_error(input_list, c, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYHXz1b3fL9J",
        "outputId": "b8583c04-234c-4ead-8649-98c054e7400e"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "1.0\n",
            "1.0\n",
            "1.5\n",
            "1.0\n",
            "1.5\n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "1.5\n",
            "1.0\n",
            "1.5\n",
            "1.0\n",
            "1.0\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for s in strs:\n",
        "  b = strs.index(s)\n",
        "  c = partial(model, b)\n",
        "  print(critical_sample_ratio(input_list, c))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqeQ5rQKkTUU",
        "outputId": "a55b2226-cd5e-4363-8607-1969c97d93a0"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "0.75\n",
            "0.75\n",
            "1.0\n",
            "0.75\n",
            "1.0\n",
            "1.0\n",
            "0.75\n",
            "0.75\n",
            "1.0\n",
            "1.0\n",
            "0.75\n",
            "1.0\n",
            "0.75\n",
            "0.75\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def lz_helper(input_str):\n",
        "\n",
        "    keys_dict = {}\n",
        "\n",
        "    ind = 0\n",
        "    inc = 1\n",
        "    while True:\n",
        "        if not (len(input_str) >= ind+inc):\n",
        "            break\n",
        "        sub_str = input_str[ind:ind + inc]\n",
        "        if sub_str in keys_dict:\n",
        "            inc += 1\n",
        "        else:\n",
        "            keys_dict[sub_str] = 0\n",
        "            ind += inc\n",
        "            inc = 1\n",
        "            # print 'Adding %s' %sub_str\n",
        "\n",
        "    return len(keys_dict)\n",
        "\n",
        "\n",
        "def lz_complexity(input_str):\n",
        "    is_only_0s_or_1s = input_str == '0' * len(input_str) or input_str == '1' * len(input_str)\n",
        "    if (is_only_0s_or_1s):\n",
        "        return math.log(len(input_str),2)\n",
        "    else:\n",
        "        return math.log(len(input_str), 2)* (lz_helper(input_str[::-1]) + lz_helper(input_str))/2\n",
        "\n",
        "\n",
        "def entropy(input_str):\n",
        "    n_0 = input_str.count('0')\n",
        "    n_1 = input_str.count('1')\n",
        "\n",
        "    N = n_0 + n_1\n",
        "\n",
        "    if n_0==0 or n_1==0:\n",
        "      return -math.log((N), 2)\n",
        "\n",
        "    return -(n_0/N)*math.log((n_0/N), 2)-(n_1/N)*math.log((n_1/N), 2)\n",
        "\n",
        "\n",
        "def flip_bit(s, index):\n",
        "    return s[:index] + ('1' if s[index] == '0' else '0') + s[index + 1:]\n",
        "\n",
        "def generate_hamming_distance_1(s):\n",
        "    return [flip_bit(s, i) for i in range(len(s))]\n",
        "\n",
        "def generate_hamming_distance_2(s):\n",
        "    distance_2 = []\n",
        "    for i in range(len(s)):\n",
        "        # Flip the first bit\n",
        "        flipped_once = flip_bit(s, i)\n",
        "        for j in range(i + 1, len(s)):\n",
        "            # Flip a second bit\n",
        "            flipped_twice = flip_bit(flipped_once, j)\n",
        "            distance_2.append(flipped_twice)\n",
        "    return distance_2\n",
        "\n",
        "def generalisation_error(input_list, model, n): # i think n is the length of input\n",
        "    C1 = 0\n",
        "    C2 = 0\n",
        "    for input in input_list:\n",
        "        hd1 = generate_hamming_distance_1(input)\n",
        "        for s in hd1:\n",
        "            C1+=abs(model(input)-model(s))\n",
        "        hd2 = generate_hamming_distance_2(input)\n",
        "        for s in hd2:\n",
        "            C2+=abs(model(input)-model(s))\n",
        "    return   (1/(n*(2**n)))*C1 +  (2/(n*(2**n)*(n-1)))*C2\n",
        "\n",
        "def critical_sample_ratio(input_list, model):\n",
        "    cr = 0\n",
        "    for input in input_list:\n",
        "        hd1 = generate_hamming_distance_1(input)\n",
        "        for s in hd1:\n",
        "            if model(input)!= model(s):\n",
        "               cr+=1\n",
        "               break\n",
        "\n",
        "    return cr/len(input_list)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7ni1Fur0bysD"
      },
      "execution_count": 65,
      "outputs": []
    }
  ]
}